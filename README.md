# üõ°Ô∏è AI Document Fraud Detection System & KYC Copilot

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=flat&logo=fastapi)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=flat&logo=streamlit)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=flat&logo=pytorch)
![Redis](https://img.shields.io/badge/redis-%23DD0031.svg?style=flat&logo=redis&logoColor=white)
![Celery](https://img.shields.io/badge/celery-%2337814A.svg?style=flat&logo=celery&logoColor=white)

An enterprise-grade, multi-modal machine learning pipeline designed to detect forged onboarding documents (salary slips, IDs, utility bills) for Fintech and Banking KYC (Know Your Customer) processes. 

This system moves beyond basic image processing by combining **Computer Vision (ViT/CNN)**, **NLP (LayoutLM/Entity Extraction)**, and **Explainable AI (Grad-CAM)** with a highly scalable, asynchronous backend.

## üöÄ Key Features

* **Multi-Modal Forgery Detection:** * **Pixel-Level:** Utilizes Error Level Analysis (ELA) and a patch-based Vision Transformer (ViT) to detect deepfakes, splicing, and digital tampering.
    * **Structural-Level:** Leverages LayoutLM to detect misaligned text blocks and unnatural bounding box spacing.
* **Digital Forensics:** Automatically extracts and analyzes hidden PDF metadata to flag documents generated by suspicious software (e.g., Photoshop, Illustrator).
* **KYC Cross-Validation:** Extracts entities (Name, Address) from multiple documents using NLP and performs fuzzy-matching to ensure data consistency across an applicant's profile.
* **Explainable AI (XAI):** Uses Grad-CAM to generate visual heatmaps, highlighting the exact pixels and artifacts that triggered the AI's "forged" decision for human review.
* **Analyst Copilot (RAG):** Built-in conversational agent backed by a Vector Database, allowing risk analysts to query internal compliance rulebooks directly from the dashboard.
* **Asynchronous Processing:** Powered by Celery and Redis to handle heavy ML inference workloads without blocking the main FastAPI thread, ensuring a seamless user experience.

## üß† System Architecture

The application is split into a highly responsive Streamlit frontend and a robust FastAPI backend, utilizing an async task queue for heavy model inference.

1. **Client:** Uploads document(s) via Streamlit UI.
2. **API Gateway:** FastAPI receives the payload and dispatches a task to Celery.
3. **Message Broker:** Redis queues the task.
4. **ML Workers:** Celery workers execute the pipeline (PDF Conversion -> OCR -> ELA -> ViT -> Grad-CAM -> LayoutLM).
5. **Results:** Stored in Redis and polled by the frontend for rendering.

## üõ†Ô∏è Tech Stack

* **Frontend:** Streamlit, Pandas (Data Structuring)
* **Backend & API:** FastAPI, Uvicorn, Pydantic
* **Async Infrastructure:** Celery, Redis
* **Computer Vision & Deep Learning:** PyTorch, torchvision, OpenCV, timm, pytorch-gradcam
* **OCR & NLP:** EasyOCR / Tesseract, Hugging Face `transformers` (LayoutLM), spaCy, thefuzz
* **RAG System:** LangChain / LlamaIndex, ChromaDB / FAISS

## üíª Local Setup & Installation

**1. Clone the repository**
`bash
git clone https://github.com/yourusername/ai-fraud-detection.git
cd ai-fraud-detection
`

**2. Create a virtual environment and install dependencies**
`bash
python -m venv venv
source venv/bin/activate  # On Windows use `venv\Scripts\activate`
pip install -r requirements.txt
`

**3. Start the Redis Server**
Make sure you have Redis installed and running locally.
`bash
redis-server
`

**4. Start the Celery Worker (New Terminal)**
`bash
celery -A core.celery_app worker --loglevel=info
`

**5. Start the FastAPI Backend (New Terminal)**
`bash
uvicorn main:app --reload --port 8000
`

**6. Start the Streamlit Frontend (New Terminal)**
`bash
streamlit run app.py
`


## ü§ù Future Enhancements
* Implement a full Docker Compose setup for one-click deployment.
* Add PostgreSQL for persistent tracking of historical scans and API key management.
* Fine-tune the Vision Transformer on a custom dataset of forged financial documents.

---
*Built by Rhythem Sharma 